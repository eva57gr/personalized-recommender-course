{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/decodingml/hands-on-recommender-system.git\n",
    "    %cd hands-on-recommender-system/\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "\n",
    "    root_dir = str(Path().absolute()) \n",
    "    print(\"‚õ≥Ô∏è Google Colab environment\")\n",
    "else:\n",
    "    root_dir = str(Path().absolute().parent)\n",
    "    print(\"‚õ≥Ô∏è Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üß¨ Train Retrieval Model </span>\n",
    "\n",
    "In this notebook, you will train a retrieval model that will be able to quickly generate a small subset of candidate items from a large collection of items. Your model will be based on the *two-tower architecture*, which embeds queries and candidates (keys) into a shared low-dimensional vector space. Here, a query consists of features of a customer and a transaction (e.g. timestamp of the purchase), whereas a candidate consists of features of a particular item. All queries will have a user ID and all candidates will have an item ID, and the model will be trained such that the embedding of a user will be close to all the embeddings of items the user has previously bought.\n",
    "\n",
    "After training the model you will save and upload its components to the Hopsworks Model Registry.\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = str(Path().absolute().parent)\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from recsys import utils\n",
    "from recsys.data import retrieval\n",
    "from recsys.models import two_tower, two_tower_serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 19:33:41.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecsys.utils\u001b[0m:\u001b[36mget_hopsworks_feature_store\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoging to Hopsworks using HOPSWORKS_API_KEY env var.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/15551\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project, fs = utils.get_hopsworks_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "In Hopsworks, you write features to feature groups (where the features are stored) and you read features from feature views. A feature view is a logical view over features, stored in feature groups, and a feature view typically contains the features used by a specific model. This way, feature views enable features, stored in different feature groups, to be reused across many different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = retrieval.create_feature_view(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view and explore data in the feature view you can retrieve batch data using the `get_batch_data()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (247.85s) \n",
      "2024-11-08 19:38:05,154 WARNING: VersionWarning: Incremented version to `9`.\n",
      "\n",
      "CPU times: user 823 ms, sys: 197 ms, total: 1.02 s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1,\n",
    "    test_size=0.1,\n",
    "    description=\"Retrieval dataset splits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will train your retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding you will use:\n",
    "- `customer_id`: ID of the customer.\n",
    "- `age`: age of the customer at the time of purchase.\n",
    "- `month_sin`, `month_cos`: time of year the purchase was made.\n",
    "\n",
    "For the candidate embedding you will use:\n",
    "- `article_id`: ID of the item.\n",
    "- `garment_group_name`: type of garment.\n",
    "- `index_group_name`: menswear/ladieswear etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = [\"customer_id\", \"age\", \"month_sin\", \"month_cos\"]\n",
    "candidate_features = [\"article_id\", \"garment_group_name\", \"index_group_name\"]\n",
    "\n",
    "\n",
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col: df[col] for col in df})\n",
    "\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE * 10)\n",
    "val_ds = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need a list of user and item IDs when you initialize your embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 88,244\n",
      "Number of users: 4,831\n",
      "Number of items: 32,051\n",
      "['Jersey Fancy', 'Knitwear', 'Accessories', 'Trousers Denim', 'Jersey Basic', 'Trousers', 'Outdoor', 'Dresses Ladies', 'Shoes', 'Blouses', 'Under-, Nightwear', 'Woven/Jersey/Knitted mix Baby', 'Socks and Tights', 'Swimwear', 'Dressed', 'Skirts', 'Shorts', 'Shirts', 'Special Offers', 'Unknown', 'Dresses/Skirts girls']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve unique customer IDs and article IDs from the training dataset\n",
    "user_id_list = train_df[\"customer_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"article_id\"].unique().tolist()\n",
    "\n",
    "# Retrieve unique garment group names and index group names from the training dataset\n",
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()\n",
    "\n",
    "# Print the number of transactions, number of users, number of items, and unique garment group names\n",
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")\n",
    "print(garment_group_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üè∞ Two Tower Model </span>\n",
    "\n",
    "The two tower model consist of two models:\n",
    "- Query model: Generates a query representation given user and transaction features.\n",
    "- Candidate model: Generates an item representation given item features.\n",
    "\n",
    "**Both models produce embeddings that live in the same embedding space**. You let this space be low-dimensional to prevent overfitting on the training data. (Otherwise, the model might simply memorize previous purchases, which makes it recommend items customers already have bought)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You start with creating the query model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.1764864 , -0.00185757, -0.12651373, -0.04278179, -0.03960358,\n",
       "         0.27857444,  0.16759372,  0.20195682, -0.08409421,  0.28024834,\n",
       "         0.05457634, -0.11726266, -0.08702008,  0.07779447, -0.12798475,\n",
       "        -0.00588928]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_model = two_tower.QueryTower(user_ids=user_id_list, emb_dim=EMB_DIM)\n",
    "# TODO: Move this inside model\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x: x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_df = train_df[query_features]\n",
    "query_ds = df_to_ds(query_df).batch(1)\n",
    "query_model(next(iter(query_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate model is very similar to the query model. A difference is that it has two categorical features as input, which you one-hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model = two_tower.ItemTower(\n",
    "    item_ids=item_id_list,\n",
    "    garment_groups=garment_group_list,\n",
    "    index_groups=index_group_list,\n",
    "    emb_dim=EMB_DIM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will evaluate the two tower model using the *top-100 accuracy*. That is, for each transaction in the validation data you will generate the associated query embedding and retrieve the set of the 100 items that are closest to this query in the embedding space. The top-100 accuracy measures how often the item that was actually bought is part of this subset. To evaluate this, you create a dataset of all unique items in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = train_df[candidate_features]\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27\">üèÉüèª‚Äç‚ôÇÔ∏è Model Training </span>\n",
    "\n",
    "You'll train our model using the AdamW optimizer, which applies weight regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-08 19:38:06,142 WARNING: At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    }
   ],
   "source": [
    "# Create a TwoTowerModel with the specified query_model and item_model\n",
    "model = two_tower.TwoTowerModel(\n",
    "    query_model, item_model, item_ds=item_ds, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Define an optimizer using AdamW with a learning rate of 0.01\n",
    "optimizer = tf.keras.optimizers.AdamW(weight_decay=0.001, learning_rate=0.01)\n",
    "\n",
    "# Compile the model using the specified optimizer\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 15088.4310 - regularization_loss: 0.0000e+00 - total_loss: 15088.4310 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 5146.0039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5146.0039\n",
      "Epoch 2/5\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 14441.7104 - regularization_loss: 0.0000e+00 - total_loss: 14441.7104 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 5109.5132 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5109.5132\n",
      "Epoch 3/5\n",
      "44/44 [==============================] - 1s 18ms/step - loss: 13799.5807 - regularization_loss: 0.0000e+00 - total_loss: 13799.5807 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 5147.0176 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5147.0176\n",
      "Epoch 4/5\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 13209.2810 - regularization_loss: 0.0000e+00 - total_loss: 13209.2810 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 5235.8242 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5235.8242\n",
      "Epoch 5/5\n",
      "44/44 [==============================] - 1s 19ms/step - loss: 12778.0821 - regularization_loss: 0.0000e+00 - total_loss: 12778.0821 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 5335.5898 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5335.5898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3629bcc90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Upload Model to Model Registry </span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to save our models locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-08 19:40:43,015 INFO: Function `compute_emb` contains input name(s) table_handle, 4347, resource with unsupported characters which will be renamed to query_tower_sequential_string_lookup_none_lookup_lookuptablefindv2_table_handle, query_tower_sequential_embedding_embedding_lookup_4347, query_tower_sequential_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:tensorflow:Assets written to: query_model/assets\n",
      "2024-11-08 19:40:43,405 INFO: Assets written to: query_model/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9445200da8714b7b92948b22a6c95349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbbc2694304451d929a18c9a561363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/56 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fea16fcef8444eb82f535ccde0cc9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/465870 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4b95e71b45406292bd54ce5355b78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/316858 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8059ef44cfa4782b0b42abaf05f6f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/561 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66a065751f445eb7d6c5c3bf49ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/166 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72a920d6504b3fbee007609755e9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/497 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/15551/models/query_model/4\n",
      "INFO:tensorflow:Assets written to: candidate_model/assets\n",
      "2024-11-08 19:41:03,055 INFO: Assets written to: candidate_model/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13978c721f4d4dd29a86613369551dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7808890f7ad454c835b4b1643239488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/56 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70879e502bea4ce4a7ecde453e8d3908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/710310 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3fd85e29474532bcb8e1a9171a6c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/2060522 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43ee39892694faea2d9e4e21073352a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/424 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc56ad78cce5408ba977f4f76aaa068f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/103 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72831c073434aceb04079357ac6e1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/448 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/15551/models/candidate_model/4\n"
     ]
    }
   ],
   "source": [
    "query_model = two_tower_serving.QueryModelModule(model.query_model)\n",
    "query_model.save_to_hopsworks(mr=mr, query_df=query_df, emb_dim=EMB_DIM)\n",
    "\n",
    "item_model = two_tower_serving.CandidateModelModule(model.item_model)\n",
    "item_model.save_to_hopsworks(mr=mr, item_df=item_df, emb_dim=EMB_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚åõÔ∏è Notebook Execution time: 483.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# End the timer\n",
    "notebook_end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "notebook_execution_time = notebook_end_time - notebook_start_time\n",
    "print(f\"‚åõÔ∏è Notebook Execution time: {notebook_execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "Retrieving the top-k closest candidate embeddings in a brute-force way (computing the distances between the query embedding and all candidate embeddings) is too expensive in a practical setting. In the next notebook, you will compute embeddings and create a feature view which will allow you to retrieve candidates with very low latency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
