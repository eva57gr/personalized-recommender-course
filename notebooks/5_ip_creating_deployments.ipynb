{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Local environment\n",
      "Adding the following directory to the PYTHONPATH: /Users/pauliusztin/Documents/01_projects/hopsworks_recsys/hands-on-recommender-system\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/decodingml/hands-on-recommender-system.git\n",
    "    %cd hands-on-recommender-system/\n",
    "\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"‚õ≥Ô∏è Google Colab environment\")\n",
    "else:\n",
    "    root_dir = str(Path().absolute().parent)\n",
    "    print(\"‚õ≥Ô∏è Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    print(f\"Adding the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference pipeline: Deploying and testing the inference pipeline \n",
    "\n",
    "In this notebook, we will dig into the inference pipeline and deploy it to Hopsworks as a real-time service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from recsys import hopsworks_integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-21 15:28:38.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecsys.hopsworks_integration.feature_store\u001b[0m:\u001b[36mget_feature_store\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mLoging to Hopsworks using HOPSWORKS_API_KEY env var.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/15551\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project, fs = hopsworks_integration.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploying the ranking inference pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You start by deploying your ranking model. Since it is a CatBoost model you need to implement a `Predict` class that tells Hopsworks how to load the model and how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28101fd845cc414f91700fd00b8da73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/4306 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473fe68b3c2a48fda5bf315a8779458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1117 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment with the same name already exists. Getting existing deployment...\n",
      "To create a new deployment choose a different name.\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment = hopsworks_integration.ranking_serving.HopsworksRankingModel.deploy(\n",
    "    project=project\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to explicitly start the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dead43dc710f4e6688dc6605446754d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/15551/deployments/335876\n",
      "\n",
      "Instance name: ranking-transformer-default-00001-deployment-6774d48698-9x9kd\n",
      "2024-11-21 13:28:57.010 7 root INFO [<module>():180] Loading serving script\n",
      "2024-11-21 13:29:00.025 7 root INFO [__init__():117] Initializing transformer for deployment: ranking\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-RC0/share/hadoop/common/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-RC0/share/hadoop/hdfs/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "2024-11-21 13:29:09.730 7 root INFO [<module>():196] Starting KServe server\n",
      "2024-11-21 13:29:09.730 7 root INFO [register_model():187] Registering model: ranking\n",
      "2024-11-21 13:29:09.731 7 root INFO [start():129] Setting max asyncio worker threads as 12\n",
      "2024-11-21 13:29:09.731 7 root INFO [serve():139] Starting uvicorn with 1 workers\n",
      "2024-11-21 13:29:10.209 7 uvicorn.error INFO [serve():84] Started server process [7]\n",
      "2024-11-21 13:29:10.209 7 uvicorn.error INFO [startup():45] Waiting for application startup.\n",
      "2024-11-21 13:29:10.211 7 root INFO [start():62] Starting gRPC server on [::]:8081\n",
      "2024-11-21 13:29:10.211 7 uvicorn.error INFO [startup():59] Application startup complete.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check logs in case of failure\n",
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> Test the ranking inference pipeline</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a dummy test example to test our ranking deployment (only the `customer_id` has to match):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['372860002', '688105013', '525518005']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranking_input = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "            \"month_sin\": 1.2246467991473532e-16,\n",
    "            \"query_emb\": [\n",
    "                0.214135289,\n",
    "                0.571055949,\n",
    "                0.330709577,\n",
    "                -0.225899458,\n",
    "                -0.308674961,\n",
    "                -0.0115124583,\n",
    "                0.0730511621,\n",
    "                -0.495835781,\n",
    "                0.625569344,\n",
    "                -0.0438038409,\n",
    "                0.263472944,\n",
    "                -0.58485353,\n",
    "                -0.307070434,\n",
    "                0.0414443575,\n",
    "                -0.321789205,\n",
    "                0.966559,\n",
    "            ],\n",
    "            \"month_cos\": -1.0,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = ranking_deployment.predict(test_ranking_input)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates, k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check logs in case of failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/15551/deployments/335876\n",
      "\n",
      "Instance name: ranking-transformer-default-00001-deployment-67f94444d8-4qgks\n",
      "2024-11-21 14:56:39.110 7 root INFO [<module>():180] Loading serving script\n",
      "2024-11-21 14:56:42.123 7 root INFO [__init__():117] Initializing transformer for deployment: ranking\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-RC0/share/hadoop/common/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/srv/hops/hadoop-3.2.0.12-EE-RC0/share/hadoop/hdfs/lib/log4j-slf4j-impl-2.19.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "2024-11-21 14:56:51.807 7 root INFO [<module>():196] Starting KServe server\n",
      "2024-11-21 14:56:51.808 7 root INFO [register_model():187] Registering model: ranking\n",
      "2024-11-21 14:56:51.808 7 root INFO [start():129] Setting max asyncio worker threads as 12\n",
      "2024-11-21 14:56:51.808 7 root INFO [serve():139] Starting uvicorn with 1 workers\n",
      "2024-11-21 14:56:52.213 7 uvicorn.error INFO [serve():84] Started server process [7]\n",
      "2024-11-21 14:56:52.213 7 uvicorn.error INFO [startup():45] Waiting for application startup.\n",
      "2024-11-21 14:56:52.215 7 root INFO [start():62] Starting gRPC server on [::]:8081\n",
      "2024-11-21 14:56:52.215 7 uvicorn.error INFO [startup():59] Application startup complete.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploying the query inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749529e0f57c422083b58a6d018593e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/2173 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment with the same name already exists. Getting existing deployment...\n",
      "To create a new deployment choose a different name.\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment = (\n",
    "    hopsworks_integration.two_tower_serving.HopsworksQueryModel.deploy(project=project)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have registered your deployment. To start it up you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5a00ba3ab6418eb2a7d6bb1c223c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/15551/deployments/335877\n",
      "\n",
      "Instance name: query-transformer-default-00001-deployment-b967dbd5d-jzcvq\n",
      "2024-11-21 13:29:37.781 7 root INFO [<module>():180] Loading serving script\n",
      "2024-11-21 13:29:40.881 7 root INFO [__init__():117] Initializing transformer for deployment: query\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "2024-11-21 13:29:41.948 7 root INFO [<module>():196] Starting KServe server\n",
      "2024-11-21 13:29:41.949 7 root INFO [register_model():187] Registering model: query\n",
      "2024-11-21 13:29:41.949 7 root INFO [start():129] Setting max asyncio worker threads as 12\n",
      "2024-11-21 13:29:41.949 7 root INFO [serve():139] Starting uvicorn with 1 workers\n",
      "2024-11-21 13:29:41.973 7 uvicorn.error INFO [serve():84] Started server process [7]\n",
      "2024-11-21 13:29:41.973 7 uvicorn.error INFO [startup():45] Waiting for application startup.\n",
      "2024-11-21 13:29:41.975 7 root INFO [start():62] Starting gRPC server on [::]:8081\n",
      "2024-11-21 13:29:41.975 7 uvicorn.error INFO [startup():59] Application startup complete.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check logs in case of failure\n",
    "query_model_deployment.get_logs(component=\"transformer\", tail=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> Testing the inference pipeline </span>\n",
    "\n",
    "Define a test input example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['474461002', '824341001', '597639006']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"instances\": {\n",
    "        \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "        \"transaction_date\": \"2022-11-15T12:16:25.330916\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_candidates = query_model_deployment.predict(data)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check logs in case of failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/15551/deployments/335877\n",
      "\n",
      "Instance name: query-transformer-default-00001-deployment-b967dbd5d-jzcvq\n",
      "2024-11-21 13:29:37.781 7 root INFO [<module>():180] Loading serving script\n",
      "2024-11-21 13:29:40.881 7 root INFO [__init__():117] Initializing transformer for deployment: query\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "2024-11-21 13:29:41.948 7 root INFO [<module>():196] Starting KServe server\n",
      "2024-11-21 13:29:41.949 7 root INFO [register_model():187] Registering model: query\n",
      "2024-11-21 13:29:41.949 7 root INFO [start():129] Setting max asyncio worker threads as 12\n",
      "2024-11-21 13:29:41.949 7 root INFO [serve():139] Starting uvicorn with 1 workers\n",
      "2024-11-21 13:29:41.973 7 uvicorn.error INFO [serve():84] Started server process [7]\n",
      "2024-11-21 13:29:41.973 7 uvicorn.error INFO [startup():45] Waiting for application startup.\n",
      "2024-11-21 13:29:41.975 7 root INFO [start():62] Starting gRPC server on [::]:8081\n",
      "2024-11-21 13:29:41.975 7 uvicorn.error INFO [startup():59] Application startup complete.\n",
      "VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "2024-11-21 13:29:52.973 7 root INFO [__call__():128] requestId: ea39f3c9-7810-4cd0-a9f5-ac92404841ef, preprocess_ms: 891.379117966, explain_ms: 0, predict_ms: 332.976579666, postprocess_ms: 4853.3411026\n",
      "2024-11-21 13:29:52.974 7 root INFO [timing():48] kserve.io.kserve.protocol.rest.v1_endpoints.predict 6.079566717147827, ['http_status:200', 'http_method:POST', 'time:wall']\n",
      "2024-11-21 13:29:52.974 7 root INFO [timing():48] kserve.io.kserve.protocol.rest.v1_endpoints.predict 0.19875700000000007, ['http_status:200', 'http_method:POST', 'time:cpu']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\"> Stopping the Hopsworks deployments </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the deployment when you're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07469daceecc4325990609fadd02e32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d58a087f6864b07922dd8b2baf88d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking_deployment.stop()\n",
    "query_model_deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> Inspecting the deployments in Hopsworks UI </span>\n",
    "\n",
    "Go to [Hopsworks UI](https://www.hopsworks.ai/), **Data Science ‚Üí Deployments** section and inspect the newly created deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-21 15:30:16.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m‚åõÔ∏è Notebook Execution time: 102.80 seconds ~ 1.71 minutes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "notebook_end_time = time.time()\n",
    "notebook_execution_time = notebook_end_time - notebook_start_time\n",
    "\n",
    "logger.info(\n",
    "    f\"‚åõÔ∏è Notebook Execution time: {notebook_execution_time:.2f} seconds ~ {notebook_execution_time / 60:.2f} minutes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\">‚Üí Next Steps </span>\n",
    "\n",
    "The last step is to schedule the materialization jobs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
