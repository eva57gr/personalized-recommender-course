{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwvbGS2HH9kg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boZoscY5H9kh"
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFcQMcMBH9ki",
    "outputId": "e69754da-1038-400e-ba28-6a9463e2c6ff"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/decodingml/hands-on-recommender-system.git\n",
    "    %cd hands-on-recommender-system/\n",
    "\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"‚õ≥Ô∏è Google Colab environment\")\n",
    "else:\n",
    "    root_dir = str(Path().absolute().parent)\n",
    "    print(\"‚õ≥Ô∏è Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    print(f\"Adding the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMbgK4H1H9kj"
   },
   "source": [
    "# Inference pipeline: Deploying and testing the LLM ranker inference pipeline\n",
    "\n",
    "In this notebook, we will dig into the inference pipeline and deploy it to Hopsworks as a real-time service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O52-H35H9kj"
   },
   "source": [
    "## üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sC7M3zMRH9kj"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from recsys import hopsworks_integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZC2bUtOH9kj"
   },
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IzZ5ZLdH9kk",
    "outputId": "e685e50c-a5d6-48a4-9543-64fd0a86e83a"
   },
   "outputs": [],
   "source": [
    "project, fs = hopsworks_integration.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMSjtySH9kk",
    "tags": []
   },
   "source": [
    "# Deploying the ranking inference pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to register your LLM ranking model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model = hopsworks_integration.llm_ranking_serving.HopsworksLLMRankingModel()\n",
    "ranking_model.register(project.get_model_registry())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-BX5lB-H9kk"
   },
   "source": [
    "Then you can deploy your LLM ranking model, which implements a `Predict` class that tells Hopsworks how to perform inference on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "28101fd845cc414f91700fd00b8da73a",
      "473fe68b3c2a48fda5bf315a8779458e"
     ]
    },
    "id": "aq5N76EPH9kk",
    "outputId": "7ccc861e-75d9-4221-fee2-ee30010fb232"
   },
   "outputs": [],
   "source": [
    "ranking_deployment = hopsworks_integration.llm_ranking_serving.HopsworksLLMRankingModel.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWnBGmXKH9kk"
   },
   "source": [
    "Now, we have to explicitly start the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "dead43dc710f4e6688dc6605446754d5"
     ]
    },
    "id": "PSbcRZMXH9kk",
    "outputId": "d438c776-bd7d-4baf-f399-0a45e468dbd3"
   },
   "outputs": [],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmH81undH9kl"
   },
   "source": [
    "## <span style=\"color:#ff5f27\"> Test the ranking inference pipeline</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfQNrNVtH9kl"
   },
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RURwh_cuH9kl"
   },
   "source": [
    "Let's define a dummy test example to test our ranking deployment (only the `customer_id` has to match):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edD5u7H_H9kl",
    "outputId": "0c3b696c-57e3-4999-835f-97e4862c0cd6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ranking_input = [\n",
    "        {\n",
    "            \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "            \"month_sin\": 1.2246467991473532e-16,\n",
    "            \"query_emb\": [\n",
    "                0.214135289,\n",
    "                0.571055949,\n",
    "                0.330709577,\n",
    "                -0.225899458,\n",
    "                -0.308674961,\n",
    "                -0.0115124583,\n",
    "                0.0730511621,\n",
    "                -0.495835781,\n",
    "                0.625569344,\n",
    "                -0.0438038409,\n",
    "                0.263472944,\n",
    "                -0.58485353,\n",
    "                -0.307070434,\n",
    "                0.0414443575,\n",
    "                -0.321789205,\n",
    "                0.966559,\n",
    "            ],\n",
    "            \"month_cos\": -1.0,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = ranking_deployment.predict(inputs=test_ranking_input)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PnYp5SeH9kl"
   },
   "source": [
    "Check logs in case of failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7n6CKYCH9kl",
    "outputId": "2153ff74-da10-4a92-80aa-b3c50f039d15"
   },
   "outputs": [],
   "source": [
    "ranking_deployment.get_logs(component=\"predictor\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the query inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model_deployment = (\n",
    "    hopsworks_integration.two_tower_serving.HopsworksQueryModel.deploy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have registered your deployment. To start it up you need to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model_deployment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> Testing the inference pipeline </span>\n",
    "\n",
    "Define a test input example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "        \"transaction_date\": \"2022-11-15T12:16:25.330916\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_candidates = query_model_deployment.predict(inputs=data)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klgFZ-G6H9ko"
   },
   "source": [
    "# <span style=\"color:#ff5f27\"> Stopping the Hopsworks deployment </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9LPUpqxH9ko"
   },
   "source": [
    "Stop the deployment when you're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "07469daceecc4325990609fadd02e32d",
      "8d58a087f6864b07922dd8b2baf88d14"
     ]
    },
    "id": "g-ZoGmMsH9ko",
    "outputId": "25b9140d-775d-47f7-a4c1-8f8c371e9d13"
   },
   "outputs": [],
   "source": [
    "ranking_deployment.stop()\n",
    "query_model_deployment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJA94BmjH9ko"
   },
   "source": [
    "## <span style=\"color:#ff5f27\"> Inspecting the deployments in Hopsworks UI </span>\n",
    "\n",
    "Go to [Hopsworks UI](https://www.hopsworks.ai/), **Data Science ‚Üí Deployments** section and inspect the newly created deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svQ_2FT6H9ko"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91SA4SmKH9ko",
    "outputId": "104d6115-c811-49ea-f51c-23be60183af8"
   },
   "outputs": [],
   "source": [
    "notebook_end_time = time.time()\n",
    "notebook_execution_time = notebook_end_time - notebook_start_time\n",
    "\n",
    "logger.info(\n",
    "    f\"‚åõÔ∏è Notebook Execution time: {notebook_execution_time:.2f} seconds ~ {notebook_execution_time / 60:.2f} minutes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti_IOOzPH9ko"
   },
   "source": [
    "# <span style=\"color:#ff5f27\">‚Üí Next Steps </span>\n",
    "\n",
    "The last step is to schedule the materialization jobs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
